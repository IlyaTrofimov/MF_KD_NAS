{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'NAS-Bench-201-v1_1-096897.pth' # set a path to NAS-Bench-201 benchmark file\n",
    "\n",
    "from nas_201_api import NASBench201API as API\n",
    "# Create an API without the verbose log\n",
    "api = API(path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "obj = pickle.load(gzip.open(open('nasbench_val.pkl.gz', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hf_val = []\n",
    "hf_test = []\n",
    "hf_times = []\n",
    "\n",
    "lf_val = []\n",
    "lf_test = []\n",
    "lf_times = []\n",
    "\n",
    "for index in range(len(api)):\n",
    "    #\n",
    "    # 200 iter\n",
    "    #\n",
    "    info = api.query_meta_info_by_index(index, hp = '200')  # This is an instance of `ArchResults`\n",
    "    \n",
    "    res_metrics = info.get_metrics('cifar10-valid', 'x-valid', 199)\n",
    "    #res_metrics = info.get_metrics('cifar100', 'x-valid', 199) \n",
    "    #res_metrics = info.get_metrics('ImageNet16-120', 'x-valid', 199) \n",
    "    hf_val.append(res_metrics['accuracy'])\n",
    "    \n",
    "    res_metrics = info.get_metrics('cifar10', 'ori-test', 199) \n",
    "    #res_metrics = info.get_metrics('cifar100', 'x-test', 199)\n",
    "    #res_metrics = info.get_metrics('ImageNet16-120', 'x-test', 199) \n",
    "    hf_test.append(res_metrics['accuracy'])\n",
    "    \n",
    "    res_metrics = info.get_metrics('cifar10-valid', 'train', 199)\n",
    "    #res_metrics = info.get_metrics('cifar100', 'train', 199)\n",
    "    #res_metrics = info.get_metrics('ImageNet16-120', 'train', 199)\n",
    "    hf_times.append(res_metrics['all_time'])\n",
    "    \n",
    "    #\n",
    "    # 12 iter\n",
    "    #\n",
    "    info = api.query_meta_info_by_index(index, hp = '12')  # This is an instance of `ArchResults`\n",
    "    res_metrics = info.get_metrics('cifar10-valid', 'x-valid', 11) \n",
    "    #res_metrics = info.get_metrics('cifar100', 'x-valid', 11) \n",
    "    #res_metrics = info.get_metrics('ImageNet16-120', 'x-valid', 11) \n",
    "    lf_val.append(res_metrics['accuracy'])\n",
    "    \n",
    "    res_metrics = info.get_metrics('cifar10', 'ori-test', 11)\n",
    "    #res_metrics = info.get_metrics('cifar100', 'x-test', 11)\n",
    "    #res_metrics = info.get_metrics('ImageNet16-120', 'x-test', 11) \n",
    "    \n",
    "    lf_test.append(res_metrics['accuracy'])\n",
    "    \n",
    "    res_metrics = info.get_metrics('cifar10-valid', 'train', 11) \n",
    "    #res_metrics = info.get_metrics('cifar100', 'train', 11)\n",
    "    #res_metrics = info.get_metrics('ImageNet16-120', 'train', 11)\n",
    "    lf_times.append(res_metrics['all_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stat(lf, hf):\n",
    "    s1 = stats.kendalltau(lf, hf).correlation\n",
    "    s2 = stats.spearmanr(lf, hf).correlation\n",
    "    s3 = stats.pearsonr(lf, hf)[0]\n",
    "\n",
    "    return [s1, s2, s3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(hf_val), max(hf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(filter(lambda x : x > 93.96, hf_test)))/len(hf_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_ep1_val = []\n",
    "\n",
    "for index in range(len(api)):    \n",
    "    info = api.query_meta_info_by_index(index, hp = '12')  # This is an instance of `ArchResults`\n",
    "    res_metrics = info.get_metrics('cifar10-valid', 'x-valid', 0)\n",
    "    #res_metrics = info.get_metrics('cifar100', 'x-valid', 0)\n",
    "    #res_metrics = info.get_metrics('ImageNet16-120', 'x-valid', 0)\n",
    "    \n",
    "    lf_ep1_val.append(res_metrics['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lf_ep1_val, open('lf_ep1_val_c10.pickle', 'wb'))\n",
    "#pickle.dump(lf_ep1_val, open('lf_ep1_val_c100.pickle', 'wb'))\n",
    "#pickle.dump(lf_ep1_val, open('lf_ep1_val_imagenet.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat(lf_ep1_val, hf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat(lf_nst_ep1, hf_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((lf_val, lf_test, hf_val, hf_test), open('acc_nb201_c10.pickle', 'wb'))\n",
    "#pickle.dump((lf_val, lf_test, hf_val, hf_test), open('acc_nb201_c100.pickle', 'wb'))\n",
    "#pickle.dump((lf_val, lf_test, hf_val, hf_test), open('acc_nb201_imagenet.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
